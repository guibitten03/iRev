{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = np.load(\"ZeroShot/.data/AMAZON_FASHION_5_zeroshot.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3176, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(\"preprocess_data/.data/AMAZON_FASHION_5.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3176, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = {i:[1,2,3] for i in range(10)}\n",
    "list(reviews.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5269, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "print(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = np.load(\"dataset/.data/All_Beauty_data_word2vec/train/itemBertDoc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 37685)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def intra_list_dissimilarity(\n",
    "    predicted: List[list], feature_df: pd.DataFrame, k: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the average intra-list dissimilarity of all recommendations.\n",
    "    This metric can be used to measure diversity of the list of recommended items.\n",
    "    Args:\n",
    "        predicted : a list of lists\n",
    "            Ordered predictions\n",
    "            Example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "        feature_df: dataframe\n",
    "            A dataframe with one hot encoded or latent features.\n",
    "            The dataframe should be indexed by the id used in the recommendations.\n",
    "        k : integer\n",
    "            The number of items to be considered at the ranking\n",
    "    Returns:\n",
    "        The average intra-list dissimilarity for recommendations.\n",
    "    \"\"\"\n",
    "    # asserts\n",
    "    assert k > 0, f\"Value k={k} is not acceptable.\"\n",
    "    assert len(predicted[0]) > 0, \"There is not any prediction.\"\n",
    "    # fill df\n",
    "    feature_df = feature_df.fillna(0)\n",
    "\n",
    "    # get all items recommended at least once that have some features\n",
    "    recs = {i for pred in predicted for i in pred}\n",
    "    recs = list(recs.intersection(feature_df.index))\n",
    "    # get their features\n",
    "    recs_content = feature_df.loc[recs]\n",
    "    recs_content = recs_content.dropna()\n",
    "\n",
    "    # save a map for each item-id\n",
    "    items_map = dict(zip(recs_content.index, np.arange(0, recs_content.shape[0])))\n",
    "    # create the sparse matrix\n",
    "    recs_content = sp.csr_matrix(np.array(recs_content.values, dtype=int))\n",
    "    # calculate similarity scores for all items recommended\n",
    "    similarity = cosine_similarity(X=recs_content, dense_output=False)\n",
    "    exceptions = []\n",
    "\n",
    "    def get_list_dissimilarity(predictions: list) -> float:\n",
    "\n",
    "        if len(predictions) > k:\n",
    "            predictions = predictions[:k]\n",
    "\n",
    "        ild_single_user = []\n",
    "        # get similarities\n",
    "        for pos, i in enumerate(predictions):\n",
    "            if i in items_map:\n",
    "                i_index = items_map[i]\n",
    "                for j in predictions[pos + 1:]:\n",
    "                    if j in items_map:\n",
    "                        j_index = items_map[j]\n",
    "                        ild_single_user.append(1.0-similarity[i_index, j_index])\n",
    "            else:\n",
    "                exceptions.append(i)\n",
    "\n",
    "        return np.mean(ild_single_user)\n",
    "\n",
    "    # Running metric\n",
    "    results = list(map(get_list_dissimilarity, predicted))\n",
    "    if len(exceptions) > 0:\n",
    "        logging.warning(f\"The podcasts {set(exceptions)} do not have any categorical feature.\")\n",
    "\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itens = [[\"x\", \"y\", \"z\"], [\"x\", \"y\", \"z\"], [\"x\", \"y\", \"z\"]]\n",
    "features = pd.DataFrame({\n",
    "    \"x1\": [1,0,0],\n",
    "    \"x2\": [0,1,0],\n",
    "    \"x3\": [0,0,1]\n",
    "\n",
    "}, index=[\"x\", \"y\", \"z\"])\n",
    "intra_list_dissimilarity(itens, features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Reshape data to fit the encoder input\n",
    "\n",
    "categories = [['apple'], ['orange'], ['banana']]\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoder.fit(categories)\n",
    "\n",
    "# Transform categories\n",
    "\n",
    "encoded_categories = encoder.transform(categories)\n",
    "\n",
    "print(encoded_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
