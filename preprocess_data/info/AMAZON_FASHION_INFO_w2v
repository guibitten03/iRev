SAVE FOLDER： ../dataset/.data/AMAZON_FASHION_data_word2vec
Warning: the word embedding file is not provided, will be initialized randomly
2023-12-10 12:08:47: Step1: loading raw review datasets...
===============Start:all  rawData size======================
dataNum: 3160
userNum: 404
itemNum: 31
data densiy: 0.2523
===============End: rawData size========================
------------------------------------------------------------
2023-12-10 12:08:47 Step2: split datsets into train/val/test, save into npy data
===============Start: no-preprocess: trainData size======================
dataNum: 2528
userNum: 404
itemNum: 30
===============End: no-preprocess: trainData size========================
===============Start--process finished: trainData size======================
dataNum: 2529
userNum (config): 404
itemNum (config): 31
===============End-process finished: trainData size========================
2023-12-10 12:08:47
Train data size (config): 2529
Val data size (config): 316
Test data size (config): 315
------------------------------------------------------------
2023-12-10 12:08:47 Step3: Construct the vocab and user/item reviews from training set.
LDA transform matrix: (435, 32)
The vocab size: 1451
Average user document length: 130.20049504950495
Average item document length: 196.80645161290323
2023-12-10 12:08:47
u_max_r:7
i_max_r:295
r_max_len：42
------------------------------------------------------------
2023-12-10 12:08:47 Step4: padding all the text and id lists and save into npy.
user document length: 500
item document length: 500
------------------------------------------------------------
2023-12-10 12:08:47 start writing npy...
2023-12-10 12:08:47 write finised
------------------------------------------------------------
2023-12-10 12:08:47 Step5: start word embedding mapping...
